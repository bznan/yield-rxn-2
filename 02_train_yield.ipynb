{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/afs/crc.nd.edu/user/m/msaebi/Public/chemistry/yield-rxn'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import json\n",
    "import rdkit.Chem as Chem\n",
    "#from rxntorch.models.reactivity_network import ReactivityNet as RxnNet, ReactivityTrainer as RxnTrainer\n",
    "#from rxntorch.utils import collate_fn\n",
    "import rdkit\n",
    "from rxntorch.containers.reaction import Rxn\n",
    "from rxntorch.containers.molecule import Mol\n",
    "from rxntorch.containers.dataset import RxnGraphDataset as RxnGD\n",
    "from rxntorch.utils import collate_fn\n",
    "from rxntorch.models.yield_network import YieldNet as RxnNet, YieldTrainer as RxnTrainer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import randperm\n",
    "from torch._utils import _accumulate\n",
    "from torch.utils.data import Dataset,Subset\n",
    "def utils_random_split(dataset, lengths,generator):\n",
    "    r\"\"\"\n",
    "    Randomly split a dataset into non-overlapping new datasets of given lengths.\n",
    "    \"\"\"\n",
    "    # Cannot verify that dataset is Sized\n",
    "    if sum(lengths) != len(dataset):  # type: ignore\n",
    "        raise ValueError(\"Sum of input lengths does not equal the length of the input dataset!\")\n",
    "\n",
    "    indices = randperm(sum(lengths), generator=generator).tolist()\n",
    "    return [Subset(dataset, indices[offset - length : offset]) for offset, length in zip(_accumulate(lengths), lengths)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-ud', '--use_domain'], dest='use_domain', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='use domain features or not', metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument(\"-p\", \"--dataset_path\", type=str, default='./data/', help=\"train dataset\")\n",
    "#parser.add_argument(\"-mp\",\"--mol_path\", type=str, default='doyle_reaction_mols', help=\"path to mol files\")\n",
    "\n",
    "parser.add_argument(\"-c\", \"--train_dataset\", required=True, type=str, help=\"train dataset\")\n",
    "parser.add_argument(\"-t\", \"--test_dataset\", type=str, default=None, help=\"test set\")\n",
    "parser.add_argument(\"-op\", \"--output_path\", type=str, default='./output/', help=\"saved model path\")\n",
    "parser.add_argument(\"-o\", \"--output_name\", required=True, type=str, help=\"e.g. rxntorch.model\")\n",
    "parser.add_argument(\"-ds\", \"--train_split\", type=float, default=0.7, help=\"Ratio of samples to reserve for test data\")\n",
    "parser.add_argument(\"-vs\", \"--valid_split\", type=float, default=0.333, help=\"Ratio of samples to reserve for valid data\")\n",
    "parser.add_argument(\"-dr\", \"--dropout_rate\", type=float, default=0.333, help=\"Ratio of samples to reserve for valid data\")\n",
    "\n",
    "parser.add_argument(\"-b\", \"--batch_size\", type=int, default=40, help=\"number of batch_size\")\n",
    "parser.add_argument(\"-tb\", \"--test_batch_size\", type=int, default=None, help=\"batch size for evaluation\")\n",
    "parser.add_argument(\"-e\", \"--epochs\", type=int, default=10, help=\"number of epochs\")\n",
    "parser.add_argument(\"-hs\", \"--hidden\", type=int, default=300, help=\"hidden size of model layers\")\n",
    "parser.add_argument(\"-l\", \"--layers\", type=int, default=3, help=\"number of layers\")\n",
    "\n",
    "parser.add_argument(\"--lr\", type=float, default=1e-2, help=\"learning rate of the optimizer\")\n",
    "parser.add_argument(\"-lrd\", \"--lr_decay\", type=float, default=0.9,\n",
    "                    help=\"Decay factor for reducing the learning rate\")\n",
    "parser.add_argument(\"-lrs\", \"--lr_steps\", type=int, default=10000,\n",
    "                    help=\"Number of steps between learning rate decay\")\n",
    "parser.add_argument(\"-awd\",\"--adam_weight_decay\", type=float, default=0.0, help=\"weight_decay of adam\")\n",
    "parser.add_argument(\"--adam_beta1\", type=float, default=0.9, help=\"adam first beta value\")\n",
    "parser.add_argument(\"--adam_beta2\", type=float, default=0.999, help=\"adam second beta value\")\n",
    "parser.add_argument(\"-gc\", \"--grad_clip\", type=float, default=None, help=\"value for gradient clipping\")\n",
    "parser.add_argument(\"-pw\", \"--pos_weight\", type=float, default=None, help=\"Weights positive samples for imbalance\")\n",
    "\n",
    "parser.add_argument(\"-w\", \"--num_workers\", type=int, default=4, help=\"dataloader worker size\")\n",
    "parser.add_argument(\"--with_cuda\", type=bool, default=True, help=\"training with CUDA: true, or false\")\n",
    "parser.add_argument(\"--cuda_devices\", type=int, nargs='*', default=None, help=\"CUDA device ids\")\n",
    "\n",
    "parser.add_argument(\"--log_freq\", type=int, default=50, help=\"printing loss every n iter: setting n\")\n",
    "parser.add_argument(\"--seed\", type=int, default=12, help=\"random seed\")\n",
    "parser.add_argument(\"-ud\",\"--use_domain\", type=str, required='True', help=\"use domain features or not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 10, 10, 10]) torch.Size([20, 78, 78, 10])\n",
      "torch.Size([20, 10, 10, 10]) torch.Size([20, 10, 11, 11])\n",
      "torch.Size([20, 10, 10, 10]) torch.Size([20, 10, 10, 12])\n",
      "torch.Size([20, 10, 10, 10]) torch.Size([20, 10, 10, 12])\n",
      "torch.Size([20, 10, 10, 10]) torch.Size([20, 10, 10, 16])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "source = torch.rand((20,10,10,10))\n",
    "d2=78\n",
    "l1, l2, l3, l4 =source.shape\n",
    "# now we expand to size (7, 11) by appending a row of 0s at pos 0 and pos 6, \n",
    "# and a column of 0s at pos 10\n",
    "result = F.pad(input=source, pad=(0, 0,  0, d2-l2,  0,d2-l3), mode='constant', value=0)\n",
    "print(source.shape, result.shape)\n",
    "\n",
    "\n",
    "result = F.pad(input=source, pad=(0, 1, 0, 1), mode='constant', value=0)\n",
    "print(source.shape, result.shape)\n",
    "\n",
    "result = F.pad(input=source, pad=(0, 2, 0, 0), mode='constant', value=0)\n",
    "print(source.shape, result.shape)\n",
    "\n",
    "result = F.pad(input=source, pad=(1, 1, 0, 0), mode='constant', value=0)\n",
    "print(source.shape, result.shape)\n",
    "\n",
    "\n",
    "result = F.pad(input=source, pad=(2, 4, 0, 0), mode='constant', value=0)\n",
    "print(source.shape, result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/22/21 16:37:24: ------------------------------------Dataset-------------------------------------\n",
      "04/22/21 16:37:24: Loading Dataset su/su_reactions_data.json in data/\n",
      "04/22/21 16:37:53: Dataset contains 4620 total samples\n",
      "04/22/21 16:37:53: 4620 number of appends \n",
      "04/22/21 16:37:53: 85 max number of atoms \n"
     ]
    }
   ],
   "source": [
    "#args = parser.parse_args()\n",
    "data_type='su'\n",
    "#args = parser.parse_args(args=['-p','data/','-c', data_type+'_reactions_data.json', '-o', 'model.01','-ud', 'False'])\n",
    "args = parser.parse_args(args=['-p','data/','-c', data_type+'/'+data_type+'_reactions_data.json', '-o', 'model.01','-ud', 'True'])\n",
    "random_seed=args.seed\n",
    "#args.dataset_path=\"/afs/crc.nd.edu/user/m/msaebi/Public/Chem/yield-rxn/data/\"\n",
    "#args.train_dataset=\"doyle_reactions_data.json\"\n",
    "args.output_name=\"reactivity.model\"\n",
    "\n",
    "if not os.path.exists(args.output_path):\n",
    "    os.mkdir(args.output_path)\n",
    "outputfile = os.path.join(args.output_path, args.output_name)\n",
    "logfile = '.'.join((args.output_name, \"log\"))\n",
    "logpath = os.path.join(args.output_path, logfile)\n",
    "logging.basicConfig(level=logging.INFO, style='{', format=\"{asctime:s}: {message:s}\",\n",
    "                    datefmt=\"%m/%d/%y %H:%M:%S\", handlers=(\n",
    "                    logging.FileHandler(logpath), logging.StreamHandler()))\n",
    "\n",
    "logging.info(\"{:-^80}\".format(\"Dataset\"))\n",
    "dataset = RxnGD(args.train_dataset, args.dataset_path, args.use_domain)\n",
    "sample = dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atom_feats  torch.Size([49, 27])\n",
      "bond_feats  torch.Size([54, 5])\n",
      "charge_feats  torch.Size([85, 85])\n",
      "nmr_feats  torch.Size([85, 85])\n",
      "atom_graph  torch.Size([49, 15])\n",
      "bond_graph  torch.Size([49, 15])\n",
      "domain_feats  torch.Size([1, 361])\n",
      "binary_feats  torch.Size([15, 15, 15])\n"
     ]
    }
   ],
   "source": [
    "print('atom_feats ', sample['atom_feats'].shape)\n",
    "print('bond_feats ', sample['bond_feats'].shape) \n",
    "print('charge_feats ', sample['charge_feats'].shape)\n",
    "print('nmr_feats ', sample['nmr_feats'].shape)\n",
    "print('atom_graph ', sample['atom_graph'].shape)\n",
    "print('bond_graph ', sample['bond_graph'].shape)\n",
    "print('domain_feats ', sample['domain_feats'].shape)\n",
    "print(\"binary_feats \", sample[\"binary_feats\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "import math\n",
    "data_type='su/su'\n",
    "mol_path= 'data/'+data_type+ '_reaction_mols'\n",
    "max_nmr=0\n",
    "max_ch=0\n",
    "min_nmr=math.inf\n",
    "min_ch=math.inf\n",
    "import glob\n",
    "import re\n",
    "\n",
    "def get_atom_mapping_doyle(mol_dir):\n",
    "    \n",
    "    smiles_mapping=defaultdict(dict) \n",
    "    if 'doyle' in mol_dir:\n",
    "        mol_dir=mol_dir.replace('.sdf','.mol')\n",
    "        print(mol_dir)\n",
    "    for mol_fn in glob.glob(mol_dir):\n",
    "        atoms , labels, atom_mapping =[], [], []\n",
    "        \n",
    "        m = Chem.MolFromMolFile(mol_fn)\n",
    "        smiles=Chem.MolToSmiles(m)\n",
    "        mol_lines=open(mol_fn,'r').readlines()\n",
    "        counter=defaultdict(int)\n",
    "        for i,line in enumerate(mol_lines[4:]):\n",
    "            l=re.sub(' +', ' ', line.strip('\\n')).split(' ')\n",
    "            if len(l)>10:\n",
    "                if len(l)==17:\n",
    "                    atom=l[4]\n",
    "                    if atom !='' and '*' not in atom and 'H' not in atom:     \n",
    "                        atoms.append(atom)\n",
    "                        counter[atom]+=1\n",
    "                        labels.append(atom+str(counter[atom]))\n",
    "                #if \"atom_labels\" in line: # for Doyle\n",
    "                    #labels=[i.strip('*') for i in mol_lines[i+1+4].strip('\\n').split(' ') if ((i!='') and ('H' not in i))]\n",
    "                    \n",
    "        if len(atoms)==len(labels):\n",
    "            for i in range(len(atoms)):\n",
    "                atom_mapping.append((atoms[i],labels[i]))            \n",
    "        else:\n",
    "            print('Atoms and lables don\\'t match')\n",
    "            print(len(atoms),len(labels))\n",
    "            atom_mapping=[]\n",
    "\n",
    "        if smiles not in smiles_mapping:\n",
    "            smiles_mapping[mol_fn.split('/')[-1].split('.')[0]]=atom_mapping\n",
    "        else:\n",
    "            print(\"key exsists\")\n",
    "    return smiles_mapping\n",
    "\n",
    "if True:    \n",
    "    def get_atom_domain_features(mol_obj,smiles_mapping,mol_path):\n",
    "        p_charge_dict=defaultdict(float)\n",
    "        nmr_dict=defaultdict(float)\n",
    "        #print(\"\\nmol_obj.smile \",mol_obj.smile)\n",
    "        #print(\"\\mol_obj.org_smile \",mol_obj.org_smile)\n",
    "        for atom in mol_obj.atoms: # first get all partial charges for different atom labels\n",
    "            if 'partial_charge' in atom:\n",
    "                p_charge_dict[atom['name']]=atom['partial_charge']\n",
    "                #print(atom['name'],atom['partial_charge'])\n",
    "            else:\n",
    "                print('crap')\n",
    "            if 'nmr_shift' in atom:\n",
    "                nmr_dict[atom['name']]=atom['nmr_shift']\n",
    "            else:\n",
    "                print('crrp')\n",
    "                    \n",
    "        partial_charges = [];nmr_shifts = []\n",
    "        name = mol_obj.name\n",
    "        if 'dy' in mol_path:\n",
    "            name = mol_obj.name\n",
    "            mol = Chem.MolFromMolFile(mol_path+'/'+name+'.mol')\n",
    "            #print(mol_path+'/'+name+'.mol')\n",
    "        if 'az' in mol_path:\n",
    "            name= mol_obj.cid\n",
    "            mol = Chem.MolFromMolFile(mol_path+'/'+name+'.sdf')\n",
    "        elif 'su' in mol_path:\n",
    "            name = mol_obj.name\n",
    "            #print(mol_path+'/'+name+'.sdf')\n",
    "            mol = Chem.MolFromMolFile(mol_path+'/'+name+'.sdf')\n",
    "\n",
    "            \n",
    "        smiles= Chem.MolToSmiles(mol)\n",
    "        #print('rdkit smile ',smiles)\n",
    "        for atom in mol.GetAtoms():\n",
    "            atom_label = smiles_mapping[name][atom.GetIdx()][1]\n",
    "            partial_charges.append(float(p_charge_dict[atom_label]))\n",
    "            nmr_shifts.append(float(nmr_dict[atom_label]))\n",
    "        \n",
    "        return smiles, nmr_shifts, partial_charges#domain_feats\n",
    "    \n",
    "smiles_mapping = get_atom_mapping_doyle(\"data/\"+data_type+\"_reaction_mols/*.sdf\")\n",
    "\n",
    "    \n",
    "with open(os.path.join('data/', data_type+'_reactions_data.json')) as datafile:\n",
    "    data = json.load(datafile)\n",
    "    lines= data\n",
    "for line in lines:\n",
    "    reactants=line['reactants']\n",
    "    \n",
    "    rxn = Rxn(line['Id'],reactants,line['yield'])\n",
    "    smiles= rxn.reactants_smile\n",
    "    #print(smiles)\n",
    "    mol=Chem.MolFromSmiles(smiles)\n",
    "    new_smiles= Chem.MolToSmiles(mol)\n",
    "    #print(new_smiles)\n",
    "    reactants=rxn.reactants # is a mol_obj\n",
    "    rxn_feats=defaultdict(lambda:defaultdict())\n",
    "\n",
    "    domain_dict= defaultdict(list)\n",
    "    for molecule in reactants:\n",
    "        \n",
    "        smiles, nmr_shifts, partial_charges = get_atom_domain_features(molecule,smiles_mapping,mol_path)\n",
    "        domain_dict[smiles]=[nmr_shifts, partial_charges]\n",
    "        \n",
    "    nmr_features=[]\n",
    "    charge_features = []\n",
    "    for react_smiles in rxn.reactants_smile_sp.split('#'):\n",
    "        #react_smiles = react['smiles']\n",
    "        #mol=Chem.MolFromSmiles(react['smiles'])\n",
    "        #react_smiles= Chem.MolToSmiles(mol)\n",
    "\n",
    "\n",
    "        nmr_features.extend(domain_dict[react_smiles][0])\n",
    "        charge_features.extend(domain_dict[react_smiles][1])\n",
    "            \n",
    "    nmr_features = torch.tensor(nmr_features).unsqueeze(0).T\n",
    "    charge_features = torch.tensor(charge_features).unsqueeze(0).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mol_file='data/su/su_reaction_mols/dtbpf.sdf'\n",
    "m1 = Chem.MolFromMolFile(mol_file)\n",
    "smiles_1=Chem.MolToSmiles(m1)\n",
    "\n",
    "m2 =Chem.MolFromSmiles('CC(C)(C)P([C]1C=C[CH][C@@H]1[Fe]C1C=CC=C1P(C(C)(C)C)C(C)(C)C)C(C)(C)C')\n",
    "smiles_2=Chem.MolToSmiles(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/22/21 16:37:53: ----------------------------------Data loaders----------------------------------\n",
      "04/22/21 16:37:53: Batch size: 40  Workers: 4  Shuffle per epoch: True\n",
      "04/22/21 16:37:53: Drop incomplete batches: True\n",
      "04/22/21 16:37:53: -------------------------------------Model--------------------------------------\n",
      "04/22/21 16:37:53: Graph convolution layers: 3  Hidden size: 300\n"
     ]
    }
   ],
   "source": [
    "afeats_size, bfeats_size, binary_size, dmfeats_size = (sample[\"atom_feats\"].shape[-1], sample[\"bond_feats\"].shape[-1],\n",
    "                                        sample[\"binary_feats\"].shape[-1], sample['domain_feats'].shape[-1])\n",
    "charge_size, nmr_size = sample['charge_feats'].shape[-1], sample['nmr_feats'].shape\n",
    "d1,d2,d3 = sample[\"binary_feats\"].shape\n",
    "binary_size= d3*d2\n",
    "\n",
    "\n",
    "logging.info(\"{:-^80}\".format(\"Data loaders\"))\n",
    "logging.info(\"Batch size: {:d}  Workers: {:d}  Shuffle per epoch: {}\".format(args.batch_size, args.num_workers, True))\n",
    "logging.info(\"Drop incomplete batches: {}\".format(True))\n",
    "\n",
    "train_dataloader = DataLoader(dataset, batch_size=args.batch_size, num_workers=args.num_workers, shuffle=True,\n",
    "                              collate_fn=collate_fn, drop_last=True)\n",
    "\n",
    "test_batch_size = args.test_batch_size if args.test_batch_size is not None else args.batch_size\n",
    "#test_dataloader = DataLoader(test_set, batch_size=test_batch_size, num_workers=args.num_workers, collate_fn=collate_fn)\n",
    "#valid_dataloader = DataLoader(valid_set, batch_size=test_batch_size, num_workers=args.num_workers, collate_fn=collate_fn)\n",
    "logging.info(\"{:-^80}\".format(\"Model\"))\n",
    "logging.info(\"Graph convolution layers: {}  Hidden size: {}\".format(\n",
    "    args.layers, args.hidden, args.batch_size, args.epochs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/22/21 16:37:53: Total Parameters: 913,803\n",
      "04/22/21 16:37:53: ------------------------------------Trainer-------------------------------------\n",
      "04/22/21 16:37:53: Optimizer: Adam  Beta1: 0.9  Beta2: 0.999\n",
      "04/22/21 16:37:53: Learning rate: 0.01  Learning rate decay: 0.9  Steps between updates: 10000\n",
      "04/22/21 16:37:53: Weight decay: 0.0 , Dropout Rate: 0.333, Gradient clipping: None  Positive sample weighting: None\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(random_seed)\n",
    "net = RxnNet(depth=args.layers, dropout=args.dropout_rate, afeats_size=afeats_size, bfeats_size=bfeats_size,\n",
    "             charge_size= charge_size, nmr_size= nmr_size,\n",
    "             hidden_size=args.hidden, binary_size=binary_size,dmfeats_size=dmfeats_size, use_domain=args.use_domain)\n",
    "logging.info(\"Total Parameters: {:,d}\".format(sum([p.nelement() for p in net.parameters()])))\n",
    "\n",
    "logging.info(\"{:-^80}\".format(\"Trainer\"))\n",
    "logging.info(\"Optimizer: {}  Beta1: {}  Beta2: {}\".format(\"Adam\", args.adam_beta1, args.adam_beta2))\n",
    "logging.info(\"Learning rate: {}  Learning rate decay: {}  Steps between updates: {}\".format(\n",
    "    args.lr, args.lr_decay, args.lr_steps))\n",
    "logging.info(\"Weight decay: {} , Dropout Rate: {}, Gradient clipping: {}  Positive sample weighting: {}\".format(\n",
    "    args.adam_weight_decay, args.dropout_rate, args.grad_clip, args.pos_weight))\n",
    "trainer = RxnTrainer(net, lr=args.lr, betas=(args.adam_beta1, args.adam_beta2), weight_decay=args.adam_weight_decay,\n",
    "                     with_cuda=args.with_cuda, cuda_devices=args.cuda_devices, log_freq=args.log_freq,\n",
    "                     grad_clip=args.grad_clip, pos_weight=args.pos_weight, lr_decay=args.lr_decay,\n",
    "                     lr_steps=args.lr_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/22/21 16:37:53: ------------------------------------Training------------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "bool value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3f7d08e48fbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mr2_train\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m#trainer.save(epoch, args.output_name, args.output_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0ma2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Public/chemistry/yield-rxn/rxntorch/models/yield_network.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, epoch, data_loader)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m#r2 ,loss,w1,w2= self.iterate(epoch, data_loader, train=True,valid=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mr2\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;31m#,w1,w2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Public/chemistry/yield-rxn/rxntorch/models/yield_network.py\u001b[0m in \u001b[0;36miterate\u001b[0;34m(self, epoch, data_loader, train, valid)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;31m#criteria=nn.SmoothL1Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mcriteria\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL1Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myield_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'yield_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yieldrxn/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL1Loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yieldrxn/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yieldrxn/lib/python3.6/site-packages/torch/nn/_reduction.py\u001b[0m in \u001b[0;36mlegacy_get_string\u001b[0;34m(size_average, reduce, emit_warning)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: bool value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "a2,b2=[],[]\n",
    "\n",
    "train_scores =[]\n",
    "test_scores =[]\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    r2_train= trainer.train_epoch(epoch, train_dataloader)\n",
    "    #trainer.save(epoch, args.output_name, args.output_path)\n",
    "    a2, b2, r2_test = trainer.test_epoch(epoch, test_dataloader)\n",
    "    train_scores.append(r2_train)\n",
    "    test_scores.append(r2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/afs/crc.nd.edu/user/m/msaebi/anaconda3/envs/yieldrxn/lib/python3.6/site-packages/torch/nn/_reduction.py\u001b[0m(36)\u001b[0;36mlegacy_get_string\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     34 \u001b[0;31m        \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     35 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 36 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     37 \u001b[0;31m        \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     38 \u001b[0;31m    \u001b[0;32melif\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  عح\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'عح' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/afs/crc.nd.edu/user/m/msaebi/anaconda3/envs/yieldrxn/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m(12)\u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     10 \u001b[0;31m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     11 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 12 \u001b[0;31m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     13 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     14 \u001b[0;31m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/afs/crc.nd.edu/user/m/msaebi/anaconda3/envs/yieldrxn/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m(85)\u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     83 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     84 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 85 \u001b[0;31m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL1Loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     86 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     87 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/afs/crc.nd.edu/user/m/msaebi/Public/chemistry/yield-rxn/rxntorch/models/yield_network.py\u001b[0m(117)\u001b[0;36miterate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    115 \u001b[0;31m            \u001b[0;31m#criteria=nn.SmoothL1Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    116 \u001b[0;31m            \u001b[0mcriteria\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL1Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 117 \u001b[0;31m            \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myield_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'yield_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    118 \u001b[0;31m            \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    119 \u001b[0;31m            \u001b[0mavg_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  yield_scores.unsqueez().shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** AttributeError: 'Tensor' object has no attribute 'unsqueez'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  yield_scores.unsqueeze().shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** TypeError: unsqueeze() missing 1 required positional arguments: \"dim\"\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>   yield_scores.unsqueeze(0).shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 40, 1])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>   yield_scores.squeeze(0).shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 1])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>   yield_scores.squeeze(1).shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  loss= criteria(yield_scores.squeeze(1), data['yield_label'].squeeze(1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** RuntimeError: bool value of Tensor with more than one value is ambiguous\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  yield_scores.squeeze(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5313, -1.2672, -1.2672, -0.6806, -1.1327, -0.1424,  1.6427,  1.3859,\n",
      "         1.5081, -0.2486,  0.5042,  1.2168, -0.2723,  0.5067,  0.6208, -0.5119,\n",
      "        -1.1326,  0.6877, -0.4850,  2.4150, -0.3953, -0.7232, -0.1891,  1.3859,\n",
      "         1.5693, -0.2068, -0.3945, -1.1327,  0.4755,  0.6434,  0.4430,  2.2805,\n",
      "         0.2909, -0.4116,  0.6299, -0.2656, -0.2959, -0.8151,  2.2959,  0.4430],\n",
      "       grad_fn=<SqueezeBackward1>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data['yield_label'].squeeze(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1447, 0.6698, 0.3383, 0.0000, 0.0999, 0.6926, 0.3207, 0.4131, 0.3599,\n",
      "        0.9114, 0.1045, 0.1324, 0.2808, 0.7302, 0.6219, 0.6708, 0.2221, 0.6238,\n",
      "        0.0932, 0.6455, 0.9648, 0.4180, 0.7236, 0.2672, 0.4345, 0.1361, 0.6251,\n",
      "        0.1197, 0.3642, 0.8828, 0.4360, 0.3871, 0.9660, 0.2051, 0.6995, 0.3893,\n",
      "        0.9243, 0.2952, 0.3437, 0.1414])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>   yield_scores.detach().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[ 0.53131425],\n",
      "       [-1.267163  ],\n",
      "       [-1.267163  ],\n",
      "       [-0.6806108 ],\n",
      "       [-1.1326714 ],\n",
      "       [-0.14240545],\n",
      "       [ 1.6426883 ],\n",
      "       [ 1.3859085 ],\n",
      "       [ 1.5081122 ],\n",
      "       [-0.2485538 ],\n",
      "       [ 0.50415957],\n",
      "       [ 1.2168002 ],\n",
      "       [-0.2723351 ],\n",
      "       [ 0.50674903],\n",
      "       [ 0.62080246],\n",
      "       [-0.5119051 ],\n",
      "       [-1.1326259 ],\n",
      "       [ 0.68773377],\n",
      "       [-0.4850101 ],\n",
      "       [ 2.4150364 ],\n",
      "       [-0.39530832],\n",
      "       [-0.7232326 ],\n",
      "       [-0.189107  ],\n",
      "       [ 1.3859085 ],\n",
      "       [ 1.5692625 ],\n",
      "       [-0.2068181 ],\n",
      "       [-0.3944943 ],\n",
      "       [-1.1326714 ],\n",
      "       [ 0.4754995 ],\n",
      "       [ 0.6434095 ],\n",
      "       [ 0.44301033],\n",
      "       [ 2.2804608 ],\n",
      "       [ 0.29094768],\n",
      "       [-0.41158468],\n",
      "       [ 0.6299432 ],\n",
      "       [-0.2655996 ],\n",
      "       [-0.29590997],\n",
      "       [-0.8151479 ],\n",
      "       [ 2.295905  ],\n",
      "       [ 0.44301033]], dtype=float32)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  loss= criteria(yield_scores.detach().numpy(), data['yield_label'].detach().numpy())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  yield_scores.detach().numpy().shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 1)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(name,torch.sum(pram.data)) for name, param in self.model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/'+args.output_name+'_y_true.txt', 'w') as f_true, open('data/'+args.output_name+'_y_pred.txt', 'w') as f_pred:\n",
    "    f_true.write(','.join(map(str, [float(n[0]) for n in a2])))\n",
    "    f_pred.write(','.join(map(str, [float(n[0]) for n in b2])))\n",
    "    \n",
    "    \n",
    "with open('data/'+args.output_name+'_train_scores.txt', 'w') as train_r2, open('data/'+args.output_name+'_test_scores.txt', 'w') as test_r2:\n",
    "    train_r2.write(','.join(map(str, [float(n) for n in train_scores])))\n",
    "    test_r2.write(','.join(map(str, [float(n) for n in test_scores])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score( data['yield_label'].cpu(), yield_scores.cpu().detach().numpy() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=300x300 at 0x7FB2F30072E8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdkit.Chaem import Draw\n",
    "Draw.MolToImage(mol)\n",
    "#Chem.FindMolChiralCenters(mol,force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C 0\n",
      "C 1\n",
      "C 2\n",
      "C 3\n",
      "C 4\n",
      "C 5\n",
      "C 6\n",
      "C 7\n",
      "Br 8\n"
     ]
    }
   ],
   "source": [
    "m = Chem.MolFromMolFile('data/doyle_reaction_mols/1-bromo-4-ethylbenzene.mol')\n",
    "m.GetNumAtoms()\n",
    "AllChem.Compute2DCoords(m)\n",
    "for atom in m.GetAtoms():\n",
    "    print(atom.GetSymbol(),atom.GetIdx())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "\n",
    "\n",
    "def get_atom_mapping_doyle(mol_dir):\n",
    "    \n",
    "    smiles_mapping=defaultdict(dict) \n",
    "    \n",
    "    for mol_fn in glob.glob(mol_dir):\n",
    "        atoms , labels, atom_mapping =[], [], []\n",
    "        if 'methyl-isoxazole-5-carboxylate' in mol_fn:\n",
    "            print(mol_fn)\n",
    "            m = Chem.MolFromMolFile(mol_fn)\n",
    "            smiles=Chem.MolToSmiles(m)\n",
    "            mol_lines=open(mol_fn,'r').readlines()\n",
    "\n",
    "            for i,line in enumerate(mol_lines[4:]):\n",
    "                l=re.sub(' +', ' ', line.strip('\\n'))\n",
    "                l2=l.split(' ')\n",
    "                if len(l2)==17:\n",
    "                    atom=l2[4]\n",
    "                    if atom !='' and '*' not in atom and 'H' not in atom:\n",
    "                        atoms.append(atom)\n",
    "                if \"atom_labels\" in line:\n",
    "                    labels=[i.strip('*') for i in mol_lines[i+1+4].strip('\\n').split(' ') if ((i!='') and ('H' not in i))]\n",
    "                    print(labels)\n",
    "            if len(atoms)==len(labels):\n",
    "                for i in range(len(atoms)):\n",
    "                    atom_mapping.append((atoms[i],labels[i]))            \n",
    "                print(atom_mapping)\n",
    "            else:\n",
    "                print('Atoms and lables don\\'t match')\n",
    "                atom_mapping=[]\n",
    "\n",
    "            if smiles not in smiles_mapping:\n",
    "                print(mol_fn.split('/')[-1].split('.')[0])\n",
    "                smiles_mapping[mol_fn.split('/')[-1].split('.')[0]]=atom_mapping\n",
    "            else:\n",
    "                print(\"key exsists\")\n",
    "    return smiles_mapping\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te\n"
     ]
    }
   ],
   "source": [
    "for mol_fn in glob.glob(\"data/doyle_reaction_mols/*.mol\"):\n",
    "    if 'methyl-isoxazole-5-carboxylate' in mol_fn:\n",
    "        print(\"te\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/doyle_reaction_mols/methyl-isoxazole-5-carboxylate.mol\n",
      "['O1', 'N1', 'C3', 'C4', 'C5', 'C1', 'O1', 'O2', 'C2']\n",
      "[('O', 'O1'), ('N', 'N1'), ('C', 'C3'), ('C', 'C4'), ('C', 'C5'), ('C', 'C1'), ('O', 'O1'), ('O', 'O2'), ('C', 'C2')]\n",
      "methyl-isoxazole-5-carboxylate\n"
     ]
    }
   ],
   "source": [
    "smiles_mapping=get_atom_mapping_doyle(\"data/doyle_reaction_mols/*.mol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('O', 'O1'),\n",
       " ('N', 'N1'),\n",
       " ('C', 'C3'),\n",
       " ('C', 'C4'),\n",
       " ('C', 'C5'),\n",
       " ('C', 'C1'),\n",
       " ('O', 'O1'),\n",
       " ('O', 'O2'),\n",
       " ('C', 'C2')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles_mapping['methyl-isoxazole-5-carboxylate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles_mapping['methyl-isoxazole-5-carboxylate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('C', 'C1'),\n",
       " ('C', 'C4'),\n",
       " ('C', 'C2'),\n",
       " ('C', 'C2'),\n",
       " ('C', 'C3'),\n",
       " ('C', 'C3'),\n",
       " ('C', 'C4'),\n",
       " ('C', 'C1'),\n",
       " ('Br', 'Br1')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles_mapping['1-bromo-4-ethylbenzene']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "atoms=[{\"name\": \"C1\", \"atomic_num\": 6, \"partial_charge\": -0.025, \"nmr_shift\": 132.85}, {\"name\": \"C2\", \"atomic_num\": 6, \"partial_charge\": -0.058, \"nmr_shift\": 125.36}, {\"name\": \"C3\", \"atomic_num\": 6, \"partial_charge\": -0.211, \"nmr_shift\": 122.91}, {\"name\": \"C4\", \"atomic_num\": 6, \"partial_charge\": 0.167, \"nmr_shift\": 136.02}, {\"name\": \"H2\", \"atomic_num\": 1, \"partial_charge\": 0.104, \"nmr_shift\": 7.11}, {\"name\": \"H3\", \"atomic_num\": 1, \"partial_charge\": 0.14, \"nmr_shift\": 6.97}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_charge_dict=defaultdict(float)\n",
    "nmr_dict=defaultdict(float)\n",
    "for atom in atoms:\n",
    "    p_charge_dict[atom['name']]=atom['partial_charge']\n",
    "    nmr_dict[atom['name']]=atom['nmr_shift']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {'C1': -0.025,\n",
       "             'C2': -0.058,\n",
       "             'C3': -0.211,\n",
       "             'C4': 0.167,\n",
       "             'H2': 0.104,\n",
       "             'H3': 0.14})"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_charge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=Chem.MolFromMolFile('data/doyle_reaction_mols/1-bromo-4-ethylbenzene.mol')\n",
    "partial_charges=[]\n",
    "nmr_shifts=[]\n",
    "\n",
    "for atom in m.GetAtoms():\n",
    "    atom_label=smiles_mapping['1-bromo-4-ethylbenzene'][atom.GetIdx()][1]\n",
    "    partial_charges.append(p_charge_dict[atom_label])\n",
    "    nmr_shifts.append(nmr_dict[atom_label])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.025, 0.167, -0.058, -0.058, -0.211, -0.211, 0.167, -0.025, 0.0]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[132.85, 136.02, 125.36, 125.36, 122.91, 122.91, 136.02, 132.85, 0.0]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmr_shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm=Chem.MolFromSmiles('CCc1ccc(Br)cc1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rdkit.Chem.rdchem._ROAtomSeq at 0x7fd7fa850d50>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm.GetAtoms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 C\n",
      "1 C\n",
      "2 C\n",
      "3 C\n",
      "4 C\n",
      "5 C\n",
      "6 Br\n",
      "7 C\n",
      "8 C\n"
     ]
    }
   ],
   "source": [
    "for atom in mm.GetAtoms():\n",
    "    print(atom.GetIdx(),atom.GetSymbol())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Chem.MolFromMolFile('data/doyle_reaction_mols/1-bromo-4-ethylbenzene.mol')\n",
    "m.GetNumAtoms()\n",
    "Chem.MolToSmiles(m)\n",
    "#AllChem.Compute2DCoords(m2)\n",
    "#for atom in m.GetAtoms():\n",
    "    #print(atom.GetSymbol(),atom.GetIdx())\n",
    "#print(Chem.MolToMolBlock(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "file_name = args.train_dataset\n",
    "path = args.dataset_path\n",
    "rxns = []\n",
    "degree_codec = LabelEncoder()\n",
    "symbol_codec = LabelEncoder()\n",
    "expl_val_codec = LabelEncoder()\n",
    "bond_type_codec = LabelEncoder()\n",
    "max_nbonds = 10   \n",
    "symbols = set()\n",
    "degrees = set()\n",
    "explicit_valences = set()\n",
    "bond_types = set()\n",
    "\n",
    "a=True\n",
    "charges,shifts=[math.inf,-math.inf],[math.inf,-math.inf]\n",
    "with open(os.path.join(path, file_name)) as datafile:\n",
    "    data = json.load(datafile)\n",
    "    for line in data:\n",
    "\n",
    "        product=line['product']\n",
    "        reactants=line['reactants']\n",
    "        r_yield=line['yield']\n",
    "     \n",
    "        rxn = Rxn(product,reactants,r_yield)\n",
    "        mol = Chem.MolFromSmiles(rxn.reactants_smile)\n",
    "        #atom_idx = torch.tensor([atom.GetIdx()-1 for atom in mol.GetAtoms()], dtype=torch.int64)\n",
    "\n",
    "        mol_reactants=rxn.reactants\n",
    "        for mol_idx in range(1,len(mol_reactants)):\n",
    "            current_molecule=mol_reactants[mol_idx]\n",
    "            atoms=current_molecule.atoms\n",
    "            #p_charge_dict=defaultdict(float)\n",
    "            #nmr_dict=defaultdict(float)\n",
    "            for atom in atoms:\n",
    "                if 'partial_charge' in atom:\n",
    "                    charges[0],charges[1]= min(charges[0],atom['partial_charge']), max(charges[1],atom['partial_charge'])\n",
    "                if 'nmr_shift' in atom:\n",
    "                    shifts[0],shifts[1]= min(shifts[0],atom['nmr_shift']), max(shifts[1],atom['nmr_shift'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.96, 1.858]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.41, 168.89]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yieldrxn",
   "language": "python",
   "name": "yieldrxn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
